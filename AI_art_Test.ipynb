{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coL4WLL_Jwff"
      },
      "source": [
        "CODICE PULITO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju_FeYFVJ5hQ"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.11' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/ricca/AppData/Local/Programs/Python/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpnKDWnIJ8b7"
      },
      "outputs": [],
      "source": [
        "# ✅ Check CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJZ3q8TsKAbE"
      },
      "outputs": [],
      "source": [
        "# ✅ Monta Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM-WHUsPKCFZ"
      },
      "outputs": [],
      "source": [
        "# ✅ Paths\n",
        "BASE_DIR = \"/content/drive/MyDrive/proj_cv\"\n",
        "DATASET_PATH = os.path.join(BASE_DIR, \"dataset\", \"paired_dataset_art\")\n",
        "DAMAGED_PATH = os.path.join(DATASET_PATH, \"damaged\")\n",
        "UNDAMAGED_PATH = os.path.join(DATASET_PATH, \"undamaged\")\n",
        "PROCESSED_PATH = os.path.join(BASE_DIR, \"processed_images\")\n",
        "\n",
        "os.makedirs(os.path.join(PROCESSED_PATH, \"damaged\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(PROCESSED_PATH, \"undamaged\"), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09azezNfKD3M"
      },
      "outputs": [],
      "source": [
        "# ✅ Preprocessing\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "def preprocess_image(path, denoise=True):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    if denoise:\n",
        "        img = cv2.GaussianBlur(img, (5,5), 0)\n",
        "    img = img / 255.0\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zkl2nsI7KFTk"
      },
      "outputs": [],
      "source": [
        "# ✅ Process and save images\n",
        "for img_name in os.listdir(DAMAGED_PATH):\n",
        "    damaged_path = os.path.join(DAMAGED_PATH, img_name)\n",
        "    undamaged_name = img_name.replace(\"-before\", \"-after\")\n",
        "    undamaged_path = os.path.join(UNDAMAGED_PATH, undamaged_name)\n",
        "\n",
        "    processed_damaged = preprocess_image(damaged_path)\n",
        "    cv2.imwrite(os.path.join(PROCESSED_PATH, \"damaged\", img_name), (processed_damaged * 255).astype(np.uint8))\n",
        "\n",
        "    if os.path.exists(undamaged_path):\n",
        "        processed_undamaged = preprocess_image(undamaged_path)\n",
        "        cv2.imwrite(os.path.join(PROCESSED_PATH, \"undamaged\", undamaged_name), (processed_undamaged * 255).astype(np.uint8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APUnK5mjKHLB"
      },
      "outputs": [],
      "source": [
        "# ✅ Dataset\n",
        "class ArtDataset(Dataset):\n",
        "    def __init__(self, damaged_dir, undamaged_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "\n",
        "        damaged_files = os.listdir(damaged_dir)\n",
        "        undamaged_files = set(os.listdir(undamaged_dir))  # per lookup veloce\n",
        "\n",
        "        for damaged_file in damaged_files:\n",
        "            base_name = damaged_file.replace(\"-before\", \"-after\")\n",
        "            if base_name in undamaged_files:\n",
        "                self.samples.append((damaged_file, base_name))\n",
        "\n",
        "        self.damaged_dir = damaged_dir\n",
        "        self.undamaged_dir = undamaged_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        damaged_file, undamaged_file = self.samples[idx]\n",
        "\n",
        "        damaged_img = Image.open(os.path.join(self.damaged_dir, damaged_file)).convert(\"RGB\")\n",
        "        undamaged_img = Image.open(os.path.join(self.undamaged_dir, undamaged_file)).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            damaged_img = self.transform(damaged_img)\n",
        "            undamaged_img = self.transform(undamaged_img)\n",
        "\n",
        "        return damaged_img, undamaged_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8AvHjRHKI4-"
      },
      "outputs": [],
      "source": [
        "# ✅ Model: Simple Autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 3, 2, 1), nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 3, 2, 1, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))\n",
        "\n",
        "model = Autoencoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COZwNAqfKK3U"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "dataset = ArtDataset(\n",
        "    damaged_dir=os.path.join(PROCESSED_PATH, \"damaged\"),\n",
        "    undamaged_dir=os.path.join(PROCESSED_PATH, \"undamaged\"),\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnTDtZ0jKMpt"
      },
      "outputs": [],
      "source": [
        "# ✅ Training Loop\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for damaged, undamaged in dataloader:\n",
        "        damaged, undamaged = damaged.to(device), undamaged.to(device)\n",
        "        output = model(damaged)\n",
        "        loss = criterion(output, undamaged)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg05YVh1KOGf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "\n",
        "# ✅ PSNR\n",
        "def psnr(img1, img2):\n",
        "    mse = F.mse_loss(img1, img2).item()\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * np.log10(1.0 / np.sqrt(mse))\n",
        "\n",
        "# ✅ SSIM\n",
        "def compute_ssim(img1, img2):\n",
        "    img1 = img1.permute(1, 2, 0).cpu().numpy()\n",
        "    img2 = img2.permute(1, 2, 0).cpu().numpy()\n",
        "    img1 = (img1 * 0.5 + 0.5)\n",
        "    img2 = (img2 * 0.5 + 0.5)\n",
        "    return compare_ssim(img1, img2, channel_axis=2, data_range=1.0)\n",
        "\n",
        "# ✅ Valutazione globale\n",
        "def evaluate_model_metrics(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_psnr = 0.0\n",
        "    total_ssim = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for damaged, undamaged in dataloader:\n",
        "            damaged, undamaged = damaged.to(device), undamaged.to(device)\n",
        "            restored = model(damaged)\n",
        "\n",
        "            for i in range(damaged.size(0)):\n",
        "                p = psnr(restored[i], undamaged[i])\n",
        "                s = compute_ssim(restored[i], undamaged[i])\n",
        "                total_psnr += p\n",
        "                total_ssim += s\n",
        "                num_samples += 1\n",
        "\n",
        "    avg_psnr = total_psnr / num_samples\n",
        "    avg_ssim = total_ssim / num_samples\n",
        "    print(f\"📊 Average PSNR: {avg_psnr:.2f} dB\")\n",
        "    print(f\"📊 Average SSIM: {avg_ssim:.4f}\")\n",
        "\n",
        "# ✅ Visualizzazione\n",
        "def visualize_results(model, dataloader, device, num_images=5):\n",
        "    model.eval()\n",
        "    fig, axes = plt.subplots(num_images, 3, figsize=(12, num_images * 4))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (damaged, undamaged) in enumerate(dataloader):\n",
        "            damaged, undamaged = damaged.to(device), undamaged.to(device)\n",
        "            restored = model(damaged)\n",
        "\n",
        "            for i in range(min(damaged.size(0), num_images)):\n",
        "                d_img = damaged[i].cpu().permute(1, 2, 0).numpy()\n",
        "                r_img = restored[i].cpu().permute(1, 2, 0).numpy()\n",
        "                u_img = undamaged[i].cpu().permute(1, 2, 0).numpy()\n",
        "\n",
        "                d_img = (d_img * 0.5 + 0.5)\n",
        "                r_img = (r_img * 0.5 + 0.5)\n",
        "                u_img = (u_img * 0.5 + 0.5)\n",
        "\n",
        "                axes[i, 0].imshow(d_img)\n",
        "                axes[i, 0].set_title(\"Damaged\")\n",
        "                axes[i, 1].imshow(r_img)\n",
        "                axes[i, 1].set_title(\"Restored\")\n",
        "                axes[i, 2].imshow(u_img)\n",
        "                axes[i, 2].set_title(\"Ground Truth\")\n",
        "                for ax in axes[i]:\n",
        "                    ax.axis('off')\n",
        "            break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXhvUmRVKPtZ"
      },
      "outputs": [],
      "source": [
        "#from eval_and_viz import evaluate_model_metrics, visualize_results\n",
        "\n",
        "# Valutazione delle metriche\n",
        "evaluate_model_metrics(model, dataloader, device)\n",
        "\n",
        "# Visualizzazione risultati\n",
        "visualize_results(model, dataloader, device, num_images=5)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AI_art_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
